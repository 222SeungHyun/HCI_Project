{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import\n",
    "코드를 실행하기 위한 모든 라이브러리들 import 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 15:44:40.438924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "import operator\n",
    "import shutil\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables\n",
    "환경변수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize할 크기\n",
    "image_size = 36\n",
    "\n",
    "# 한개의 element당 생성할 data 개수\n",
    "data_size = 128\n",
    "\n",
    "# data 경로\n",
    "data_path = os.getcwd() + '/../data/'\n",
    "\n",
    "# element들을 저장할 경로\n",
    "element_path = data_path + 'alphebet/'\n",
    "\n",
    "# example이 존재하는 경로\n",
    "example_path = data_path + 'ex/'\n",
    "\n",
    "# checkpoint 경로\n",
    "model_path = './ckpt.h5'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Folder\n",
    "폴더를 생성해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "/Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code\n",
      "/Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/\n",
      "['.DS_Store', 'a.png', 'b.png', 'c.png', 'd.png', 'e.png', 'f.png', 'g.png', 'h.png', 'i.png', 'j.png', 'k.png', 'l.png', 'm.png', 'n.png', 'o.png', 'p.png', 'q.png', 'r.png', 's.png', 't.png', 'u.png', 'v.png', 'w.png', 'x.png', 'y.png', 'z.png', 'zz.png']\n"
     ]
    }
   ],
   "source": [
    "def create_folder(directory):\n",
    "      if not os.path.exists(directory):\n",
    "          os.makedirs(directory)\n",
    "          return True\n",
    "      return False\n",
    "\n",
    "create_folder(element_path)\n",
    "elements = os.listdir(example_path)\n",
    "elements.sort()\n",
    "\n",
    "print(tf.__version__)\n",
    "print(os.getcwd())\n",
    "print(data_path)\n",
    "print(elements)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 늘리기\n",
    "약간의 위치변화 혹은 회전을 통한 데이터 늘리는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 zz.png /Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/alphebet/zz\n",
      "1 zz.png /Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/alphebet/zz\n",
      "2 zz.png /Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/alphebet/zz\n",
      "3 zz.png /Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/alphebet/zz\n",
      "4 zz.png /Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/alphebet/zz\n",
      "5 zz.png /Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/alphebet/zz\n",
      "6 zz.png /Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/alphebet/zz\n",
      "7 zz.png /Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/alphebet/zz\n",
      "8 zz.png /Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/alphebet/zz\n",
      "9 zz.png /Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/alphebet/zz\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        fill_mode='constant',\n",
    "        cval=255)\n",
    "\n",
    "\n",
    "for i in elements:\n",
    "    element = i.split('.')[0]\n",
    "\n",
    "    # 폴더가 존재할 경우 파일 생성X\n",
    "    if not create_folder(element_path + element):\n",
    "       continue\n",
    "    \n",
    "    # 에시 파일읽기\n",
    "    image = load_img(example_path + i)\n",
    "    x = img_to_array(image)                 # image to array\n",
    "    x = x.reshape((1,) + x.shape)           # reshape array\n",
    "    \n",
    "    if i == 'zz.png':\n",
    "      for _ in range(10):\n",
    "        path = element_path + element\n",
    "        print(_, i, path)\n",
    "        shutil.copy(example_path + i,\n",
    "                    path + '/' + element + str(_)+'.jpg')\n",
    "    else:  \n",
    "      i = 0\n",
    "\n",
    "      # save image\n",
    "      for batch in datagen.flow(x, batch_size=1,\n",
    "                                save_to_dir=element_path + element, \n",
    "                                save_prefix=element, \n",
    "                                save_format='jpg'):\n",
    "          i += 1\n",
    "          if i > (data_size / 4) * 5:\n",
    "              break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(size):\n",
    "    # data reader\n",
    "    datagen = ImageDataGenerator(rotation_range=10,\n",
    "                                 shear_range=5,\n",
    "                                 validation_split=0.2)\n",
    "    \n",
    "    # train data\n",
    "    train_generator = datagen.flow_from_directory(element_path,\n",
    "                                                  target_size=(size,size),\n",
    "                                                  subset='training')\n",
    "    \n",
    "    # validation data\n",
    "    val_generator = datagen.flow_from_directory(element_path,\n",
    "                                                target_size=(size,size),\n",
    "                                                subset='validation')\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(train, val, class_count, size = 36):\n",
    "    K.clear_session()\n",
    "\n",
    "    model_ckpt = ModelCheckpoint(model_path, save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(patience=8, verbose=1)\n",
    "    early_stop = EarlyStopping(patience=20, verbose=2)\n",
    "\n",
    "    entry = L.Input(shape=(size,size,3))\n",
    "    x = L.SeparableConv2D(64,(3,3),activation='relu',padding ='same')(entry)\n",
    "    x = L.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    x = L.SeparableConv2D(128,(3,3),activation='relu',padding ='same')(x)\n",
    "    x = L.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    x = L.SeparableConv2D(256,(2,2),activation='relu',padding ='same')(x)\n",
    "    x = L.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    x = L.Dense(256)(x)\n",
    "    x = L.LeakyReLU()(x)\n",
    "    x = L.Dense(64,kernel_regularizer=l2(2e-4))(x)\n",
    "    x = L.LeakyReLU()(x)\n",
    "    x = L.Dense(class_count,activation='softmax')(x)\n",
    "\n",
    "    model = Model(entry,x)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train,\n",
    "                        validation_data=val,\n",
    "                        epochs=999,\n",
    "                        batch_size=128,\n",
    "                        callbacks=[model_ckpt, reduce_lr, early_stop],\n",
    "                        verbose=1)\n",
    "    return history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Losses\n",
    "학습 과정에서의 loss 그래프 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_losses(hist):\n",
    "    _, loss_ax = plt.subplots(figsize=(10, 5))\n",
    "    acc_ax = loss_ax.twinx()\n",
    "    \n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "    \n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide Image\n",
    "이미지 쪼개기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_image(img_name, shape):\n",
    "    # open image\n",
    "    image = Image.open(data_path + img_name)\n",
    "    \n",
    "    # image width, height 구학기\n",
    "    # image width, height 구학기\n",
    "    width, height = image.size[0], image.size[1]\n",
    "    single_width = width / shape[1]\n",
    "    single_height = height / shape[0]\n",
    "\n",
    "    # 폴더 생성\n",
    "    create_folder(data_path + 'tmp/')\n",
    "    \n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            # 범위 지정\n",
    "            area = (j * single_width, i * single_height,\n",
    "                    single_width * (j + 1), (i + 1) * single_height)\n",
    "            \n",
    "            path = data_path + 'tmp/' + str(i * shape[1] + j) + '/data/'\n",
    "            create_folder(path)\n",
    "            cropped_img = image.crop(area)\n",
    "            cropped_img.save(path + str(i * shape[1] + j) + '.png')        # 쪼갠 이미지 저장\n",
    "\n",
    "    return shape[0] * shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Temporary Images\n",
    "임시로 생성된 이미지 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tmp_imgs():\n",
    "    try:\n",
    "        shutil.rmtree(data_path + 'tmp')\n",
    "    except:\n",
    "        print('Warning: failed to delete temporary splited images')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3343 images belonging to 27 classes.\n",
      "Found 827 images belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = load_data(image_size)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    try:\n",
    "        load_model(model_path)\n",
    "    except:\n",
    "        print('Could not find checkpoint, creating new model')\n",
    "        hist = make_model(train_generator, \n",
    "                          val_generator,\n",
    "                          len(elements),\n",
    "                          image_size)\n",
    "        show_losses(hist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integer To ASCII(Char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itoa(num):\n",
    "    if num == 26:\n",
    "        return  ' '\n",
    "    else:\n",
    "        num_tr = num+97\n",
    "        return chr(num_tr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image_name, shape):\n",
    "    # 이미지 쪼개기\n",
    "    length = divide_image(image_name, shape)\n",
    "    result = ''\n",
    "\n",
    "    generator = ImageDataGenerator()\n",
    "    image_path = data_path + 'tmp/'\n",
    "\n",
    "    for i in range(length):\n",
    "        # 쪼갠 이미지 불러오기\n",
    "        data = generator.flow_from_directory(image_path + str(i), \n",
    "                                             target_size=(image_size, image_size))\n",
    "    \n",
    "        # Predict\n",
    "        prediction = model.predict(data)[0]\n",
    "\n",
    "        # 결과 가져오기\n",
    "        predict_idx = np.argmax(prediction)\n",
    "        predict_val = prediction[predict_idx]\n",
    "        result += itoa(predict_idx)\n",
    "        \n",
    "        print('Best prediction:', predict_val, itoa(predict_idx))\n",
    "\n",
    "    print('\\nResult:', result)\n",
    "    remove_tmp_imgs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 15:50:07.987570: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-05 15:50:08.090771: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0278 - accuracy: 0.9988\n",
      "Model accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_path)\n",
    "acc = model.evaluate(val_generator)[1]\n",
    "print('Model accuracy: %.2f' % acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Best prediction: 0.9743455 u\n",
      "Found 1 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Best prediction: 0.6086586 k\n",
      "Found 1 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Best prediction: 0.9743851  \n",
      "Found 1 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 15:54:17.772809: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-05 15:54:17.841010: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-05 15:54:17.910327: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Best prediction: 0.7695469 u\n",
      "Found 1 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Best prediction: 0.47333288 m\n",
      "Found 1 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Best prediction: 0.65948033 a\n",
      "Found 1 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 15:54:18.001035: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-05 15:54:18.069755: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-05 15:54:18.139783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "Best prediction: 0.9213107  \n",
      "Found 1 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Best prediction: 0.76391906 k\n",
      "\n",
      "Result: uk uma k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 15:54:18.207149: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-05 15:54:18.292480: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "predict(model, 'text_1.jpg', (2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_venv.nosync",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
