{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import\n",
    "코드를 실행하기 위한 모든 라이브러리들 import 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "import operator\n",
    "import shutil\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables\n",
    "환경변수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize할 크기\n",
    "image_size = 36\n",
    "\n",
    "# 한개의 element당 생성할 data 개수\n",
    "data_size = 256\n",
    "\n",
    "# data 경로\n",
    "data_path = os.getcwd() + '/../data/'\n",
    "\n",
    "# element들을 저장할 경로\n",
    "element_path = data_path + 'alphebet/'\n",
    "\n",
    "# example이 존재하는 경로\n",
    "example_path = data_path + 'ex/'\n",
    "\n",
    "# checkpoint 경로\n",
    "model_path = './ckpt.h5'\n",
    "\n",
    "# debug values\n",
    "DEBUG_DONT_ERASE_TEMP       = False\n",
    "DEBUG_PRINT_ALL_PREDICTIONS = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Folder\n",
    "폴더를 생성해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "/Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code\n",
      "/Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'zz']\n"
     ]
    }
   ],
   "source": [
    "def create_folder(directory):\n",
    "      if not os.path.exists(directory):\n",
    "          os.makedirs(directory)\n",
    "          return True\n",
    "      return False\n",
    "\n",
    "create_folder(element_path)\n",
    "elements = os.listdir(example_path)\n",
    "elements.sort()\n",
    "for element in elements: \n",
    "    if element[0] == '.':\n",
    "        elements.remove(element)\n",
    "\n",
    "print(tf.__version__)\n",
    "print(os.getcwd())\n",
    "print(data_path)\n",
    "print(elements)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 늘리기\n",
    "약간의 위치변화 혹은 회전을 통한 데이터 늘리는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.05,\n",
    "        zoom_range=0.05,\n",
    "        fill_mode='nearest',\n",
    "        cval=255)\n",
    "\n",
    "\n",
    "def generate_data(file_name):\n",
    "  for element in elements: \n",
    "      # Canny edge 적용\n",
    "      canny_path = data_path + 'canny/'\n",
    "      create_folder(canny_path)\n",
    "      cv_image = cv2.imread(example_path + element + '/' + file_name + '.png')\n",
    "      cv_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\n",
    "      canny = cv2.Canny(cv_image, 100, 200)\n",
    "      cv2.imwrite(canny_path + element + file_name + '.png', canny)\n",
    "\n",
    "      # 에시 파일읽기\n",
    "      image = load_img(canny_path + element + file_name + '.png')\n",
    "      x = img_to_array(image)                 # image to array\n",
    "      x = x.reshape((1,) + x.shape)           # reshape array\n",
    "\n",
    "      if element == 'zz':\n",
    "        for _ in range(data_size):\n",
    "          path = element_path + element\n",
    "          shutil.copy(canny_path + element + file_name + '.png',\n",
    "                      path + '/' + element + str(_)+'.jpg')\n",
    "      else:  \n",
    "        i = 0\n",
    "        create_folder(element_path + element)\n",
    "\n",
    "        # save image\n",
    "        for batch in datagen.flow(x, batch_size=1,\n",
    "                                  save_to_dir=element_path + element, \n",
    "                                  save_prefix=element + file_name, \n",
    "                                  save_format='jpg'):\n",
    "            i += 1\n",
    "            if i > (data_size / 4) * 5:\n",
    "                break\n",
    "\n",
    "\n",
    "if create_folder(element_path + element):\n",
    "  generate_data('0')\n",
    "  generate_data('1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(size):\n",
    "    # data reader\n",
    "    datagen = ImageDataGenerator(rotation_range=10,\n",
    "                                 shear_range=5,\n",
    "                                 validation_split=0.2)\n",
    "    \n",
    "    # train data\n",
    "    train_generator = datagen.flow_from_directory(element_path,\n",
    "                                                  target_size=(size,size),\n",
    "                                                  subset='training')\n",
    "    \n",
    "    # validation data\n",
    "    val_generator = datagen.flow_from_directory(element_path,\n",
    "                                                target_size=(size,size),\n",
    "                                                subset='validation')\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(train, val, class_count, size = 36):\n",
    "    K.clear_session()\n",
    "\n",
    "    model_ckpt = ModelCheckpoint(model_path, save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(patience=8, verbose=1)\n",
    "    early_stop = EarlyStopping(patience=20, verbose=2)\n",
    "\n",
    "    entry = L.Input(shape=(size,size,3))\n",
    "    x = L.SeparableConv2D(64,(3,3),activation='relu',padding ='same')(entry)\n",
    "    x = L.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    x = L.SeparableConv2D(128,(3,3),activation='relu',padding ='same')(x)\n",
    "    x = L.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    x = L.SeparableConv2D(256,(2,2),activation='relu',padding ='same')(x)\n",
    "    x = L.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    x = L.Dense(256)(x)\n",
    "    x = L.LeakyReLU()(x)\n",
    "    x = L.Dense(64,kernel_regularizer=l2(2e-4))(x)\n",
    "    x = L.LeakyReLU()(x)\n",
    "    x = L.Dense(class_count,activation='softmax')(x)\n",
    "\n",
    "    model = Model(entry,x)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train,\n",
    "                        validation_data=val,\n",
    "                        epochs=999,\n",
    "                        batch_size=256,\n",
    "                        callbacks=[model_ckpt, reduce_lr, early_stop],\n",
    "                        verbose=1)\n",
    "    return history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Losses\n",
    "학습 과정에서의 loss 그래프 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_losses(hist):\n",
    "    _, loss_ax = plt.subplots(figsize=(10, 5))\n",
    "    acc_ax = loss_ax.twinx()\n",
    "    \n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "    \n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide Image\n",
    "이미지 쪼개기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_image(img_name, shape):\n",
    "    # canny edge\n",
    "    cv_image = cv2.imread(data_path + img_name)\n",
    "    cv_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\n",
    "    canny = cv2.Canny(cv_image, 80, 150)\n",
    "    cv2.imwrite(data_path + 'tmp_canny.png', canny)\n",
    "\n",
    "    # open image\n",
    "    image = Image.open(data_path + 'tmp_canny.png')\n",
    "    if not DEBUG_DONT_ERASE_TEMP:\n",
    "        os.remove(data_path + 'tmp_canny.png')\n",
    "    \n",
    "    # image width, height 구학기\n",
    "    width, height = image.size[0], image.size[1]\n",
    "    single_width = width / shape[1]\n",
    "    single_height = height / shape[0]\n",
    "\n",
    "    # 폴더 생성\n",
    "    create_folder(data_path + 'tmp/')\n",
    "    \n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            # 범위 지정\n",
    "            area = (j * single_width, i * single_height,\n",
    "                    single_width * (j + 1), (i + 1) * single_height)\n",
    "\n",
    "            path = data_path + 'tmp/' + str(i * shape[1] + j) + '/data/'\n",
    "            create_folder(path)\n",
    "            cropped_img = image.crop(area)\n",
    "            cropped_img.save(path + str(i * shape[1] + j) + '.png')        # 쪼갠 이미지 저장\n",
    "\n",
    "    return shape[0] * shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Temporary Images\n",
    "임시로 생성된 이미지 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tmp_imgs():\n",
    "    try:\n",
    "        shutil.rmtree(data_path + 'tmp')\n",
    "    except:\n",
    "        print('Warning: failed to delete temporary splited images')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13366 images belonging to 27 classes.\n",
      "Found 3329 images belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = load_data(image_size)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    try:\n",
    "        load_model(model_path)\n",
    "    except:\n",
    "        print('Could not find checkpoint, creating new model')\n",
    "        hist = make_model(train_generator, \n",
    "                          val_generator,\n",
    "                          len(elements),\n",
    "                          image_size)\n",
    "        show_losses(hist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integer To ASCII(Char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itoa(num):\n",
    "    if num == 26:\n",
    "        return  ' '\n",
    "    else:\n",
    "        num_tr = num+97\n",
    "        return chr(num_tr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image_name, shape):\n",
    "    # 이미지 쪼개기\n",
    "    length = divide_image(image_name, shape)\n",
    "    result = ''\n",
    "\n",
    "    generator = ImageDataGenerator()\n",
    "    image_path = data_path + 'tmp/'\n",
    "\n",
    "    for i in range(length):\n",
    "        # 쪼갠 이미지 불러오기\n",
    "        data = generator.flow_from_directory(image_path + str(i), \n",
    "                                             target_size=(image_size, image_size))\n",
    "    \n",
    "        # Predict\n",
    "        prediction = model.predict(data)[0]\n",
    "        if DEBUG_PRINT_ALL_PREDICTIONS:\n",
    "            print(prediction)\n",
    "\n",
    "        # 결과 가져오기\n",
    "        predict_idx = np.argmax(prediction)\n",
    "        predict_val = prediction[predict_idx]\n",
    "        result += itoa(predict_idx)\n",
    "        \n",
    "        print('Best prediction:', predict_val, itoa(predict_idx))\n",
    "\n",
    "    print('\\nResult:', result)\n",
    "    if not DEBUG_DONT_ERASE_TEMP:\n",
    "        remove_tmp_imgs()\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 15:35:22.196649: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-04 15:35:22.317764: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 3s 29ms/step - loss: 5.6077e-04 - accuracy: 1.0000\n",
      "Model accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_path)\n",
    "acc = model.evaluate(val_generator)[1]\n",
    "print('Model accuracy: %.2f' % acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Best prediction: 0.96740806 b\n",
      "Found 1 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Best prediction: 0.62546486 e\n",
      "Found 1 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Best prediction: 0.82064915 h\n",
      "Found 1 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 15:37:32.840013: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-04 15:37:32.908550: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-04 15:37:32.977216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Best prediction: 0.49368364 c\n",
      "Found 1 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Best prediction: 0.9999851 k\n",
      "Found 1 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Best prediction: 0.99232507 o\n",
      "Found 1 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 15:37:33.047406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-04 15:37:33.118985: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-04 15:37:33.196621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Best prediction: 0.9433239 t\n",
      "Found 1 images belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Best prediction: 0.4834451 y\n",
      "\n",
      "Result: behckoty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 15:37:33.269369: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-04 15:37:33.338362: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "predicted = predict(model, 'hello.jpg', (1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for 🐸Coqui Studio voices - https://coqui.ai \n",
      "Visit 🔗https://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n",
      " > tts_models/multilingual/multi-dataset/your_tts is already downloaded.\n",
      " > Model's license - CC BY-NC-ND 4.0\n",
      " > Check https://creativecommons.org/licenses/by-nc-nd/4.0/ for more info.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > External Speaker Encoder Loaded !!\n",
      " > initialization of language-embedding layers.\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > Text splitted to sentences.\n",
      "['hello']\n",
      " > Processing time: 0.7769358158111572\n",
      " > Real-time factor: 0.6930738767271697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/72/lgrwqgmx38gdffsjlwlxyzgm0000gn/T/tmpguu7c_5d.wav':\n",
      "  Duration: 00:00:01.12, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\n",
      "   0.95 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "tts_model = TTS.list_models()[0]\n",
    "tts = TTS(tts_model)\n",
    "tts.tts_to_file(text=predicted, speaker=tts.speakers[0], language='en', file_path=\"output.wav\")\n",
    "\n",
    "audio = AudioSegment.from_wav(\"output.wav\")\n",
    "play(audio)\n",
    "os.remove(\"output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_venv.nosync",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
