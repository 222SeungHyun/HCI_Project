{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "import operator\n",
    "import shutil\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "/Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code\n",
      "/Users/naburang/Desktop/Metal/tensorflow_venv.nosync/code/../data/\n",
      "['a.png', 'b.png', 'c.png', 'd.png', 'e.png', 'f.png', 'g.png', 'h.png', 'i.png', 'j.png', 'k.png', 'l.png', 'm.png', 'n.png', 'o.png', 'p.png', 'q.png', 'r.png', 's.png', 't.png', 'u.png', 'v.png', 'w.png', 'x.png', 'y.png', 'z.png', 'zz.png']\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(os.getcwd())\n",
    "\n",
    "def create_folder(directory):\n",
    "      if not os.path.exists(directory):\n",
    "          os.makedirs(directory)\n",
    "          return True\n",
    "      return False\n",
    "\n",
    "data_path = os.getcwd() + '/../data/'\n",
    "alphabet_path = data_path + 'alphebet/'\n",
    "create_folder(alphabet_path)\n",
    "\n",
    "alphabet_list = os.listdir(data_path + 'ex/')\n",
    "alphabet_list.sort()\n",
    "\n",
    "img_size = 36\n",
    "\n",
    "print(data_path)\n",
    "print(alphabet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.05,\n",
    "        zoom_range=0.01,\n",
    "        fill_mode='constant',\n",
    "        cval=255)\n",
    "\n",
    "\n",
    "for j in alphabet_list:\n",
    "    alpha = j.split('.')[0]\n",
    "    if not create_folder(alphabet_path + alpha):\n",
    "       break\n",
    "    \n",
    "    img = load_img(data_path + 'ex/' + j)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    \n",
    "    if j == 'zz.png':\n",
    "      for _ in range(10):\n",
    "        print(_,j, alphabet_path + alpha)\n",
    "        shutil.copy(data_path + 'ex/' + j, \n",
    "                    alphabet_path + alpha + '/' + alpha + str(_)+'.jpg')\n",
    "    else:  \n",
    "      i = 0\n",
    "      for batch in datagen.flow(x, batch_size=1,\n",
    "                                save_to_dir=alphabet_path + alpha, \n",
    "                                save_prefix=alpha, \n",
    "                                save_format='jpg'):\n",
    "          i += 1\n",
    "          if i > 20:\n",
    "              break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(size):\n",
    "    datagen = ImageDataGenerator(rotation_range=10,\n",
    "                                 shear_range=5,\n",
    "                                 validation_split=0.3)\n",
    "    train_generator = datagen.flow_from_directory(alphabet_path,\n",
    "                                                  target_size=(size,size),\n",
    "                                                  subset='training')\n",
    "    val_generator = datagen.flow_from_directory(alphabet_path,\n",
    "                                                target_size=(size,size),\n",
    "                                                subset='validation')\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(train,val, class_count, size = 36):\n",
    "    K.clear_session()\n",
    "\n",
    "    model_ckpt = ModelCheckpoint('ckpt.h5',save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(patience=8,verbose=1)\n",
    "    early_stop = EarlyStopping(patience=20,verbose=2)\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    entry = L.Input(shape=(size,size,3))\n",
    "    x = L.SeparableConv2D(64,(3,3),activation='relu',padding ='same')(entry)\n",
    "    x = L.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    x = L.SeparableConv2D(128,(3,3),activation='relu',padding ='same')(x)\n",
    "    x = L.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    x = L.SeparableConv2D(256,(2,2),activation='relu',padding ='same')(x)\n",
    "    x = L.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    x = L.Dense(256)(x)\n",
    "    x = L.LeakyReLU()(x)\n",
    "    x = L.Dense(64,kernel_regularizer=l2(2e-4))(x)\n",
    "    x = L.LeakyReLU()(x)\n",
    "    x = L.Dense(class_count,activation='softmax')(x)\n",
    "\n",
    "    model = Model(entry,x)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train,\n",
    "                        validation_data=val,\n",
    "                        epochs=999,\n",
    "                        callbacks=[model_ckpt,reduce_lr,early_stop],\n",
    "                        verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_losses(hist):\n",
    "    _, loss_ax = plt.subplots(figsize=(10, 5))\n",
    "    acc_ax = loss_ax.twinx()\n",
    "    \n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "    \n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    try:\n",
    "        load_model('ckpt.h5')\n",
    "    except:\n",
    "        train_generator, val_generator = prepare_data(img_size)\n",
    "        hist = make_model(train_generator, \n",
    "                          val_generator,\n",
    "                          len(alphabet_list),\n",
    "                          img_size)\n",
    "        show_losses(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('ckpt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_num = 0\n",
    "\n",
    "def devide_img(img_name):\n",
    "    img = Image.open(data_path + img_name)\n",
    "    width, height = img.size[0], img.size[1]\n",
    "    length = int(width / height)\n",
    "\n",
    "    area = (0 + call_num * height, 0,\n",
    "            width / length * (call_num + 1), height)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_venv.nosync",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
